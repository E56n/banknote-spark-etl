# ğŸ“Œ Banknote Authentication ETL with PySpark & AWS (Free Tier)

## ğŸ“ DescripciÃ³n del Proyecto

Un pipeline ETL completo desarrollado con PySpark, que procesa datos del dataset **Banknote Authentication** (UCI / Kaggle) en un entorno profesional basado en AWS (nivel gratuito).  
El flujo incluye:

- Lectura desde **AWS S3**
- Limpieza y transformaciÃ³n de datos
- Entrenamiento de modelo de clasificaciÃ³n (Logistic Regression u otros)
- Almacenamiento de resultados en formato **Parquet**
- Consultas en **Athena**
- Pruebas automatizadas para garantizar calidad y rendimiento

---

## ğŸ¯ Objetivo

Construir una soluciÃ³n tÃ©cnica reproducible que demuestre dominio en:

- Procesamiento distribuido
- Modelado predictivo
- OrquestaciÃ³n en AWS
- Buenas prÃ¡cticas de ingenierÃ­a de datos y software

---

## ğŸ§° TecnologÃ­as utilizadas

- **PySpark (Spark 3.x)**: para ETL y Machine Learning
- **AWS Free Tier**:
  - Amazon S3
  - EMR (t2.micro o local)
  - Athena
  - CloudWatch
- **Parquet** como formato de salida
- **pytest** para validaciÃ³n y pruebas unitarias
- *(Opcional)* Great Expectations o PyDeequ para chequeo de calidad de datos
- *(Opcional)* EventBridge o Step Functions para orquestaciÃ³n

---

## ğŸš€ Flujo del pipeline

1. **Ingesta**: carga de `BankNoteAuthentication.csv` a `s3://<tu-bucket>/raw/`
2. **ETL Spark**:
   - Casteo de tipos
   - Filtrado de clases vÃ¡lidas
   - Ensamble de features
3. **Modelado ML**:
   - Pipeline con ensamblado, escalado y regresiÃ³n logÃ­stica
4. **Salida**: escritura de resultados curados en `s3://<tu-bucket>/curated/` en formato Parquet
5. **Consultas**: ejecuciÃ³n de SQL en Athena sobre los datos curados
6. **Monitoreo**: logs de ejecuciÃ³n con CloudWatch
7. **AutomatizaciÃ³n** *(opcional)*: EventBridge / Step Functions / Control-M
8. **ValidaciÃ³n**: pruebas con PyTest y calidad con herramientas como Great Expectations

---
## ğŸ“ˆ MÃ©tricas y resultados esperados

- PrecisiÃ³n esperada del modelo >â€¯95â€¯%
- Conteos por clase y matriz de confusiÃ³n consultables desde Athena
- Reportes de calidad: nulos, duplicados, rangos vÃ¡lidos
- Logs de ejecuciÃ³n y performance desde EMR/CloudWatch

---

## ğŸ§¾ Â¿Por quÃ© incluir este proyecto en tu portafolio?

- Demuestra experiencia en **PySpark**, **AWS S3/EMR/Athena**
- Caso real de **ETL + ML** de inicio a fin
- Incluye pruebas, validaciones y automatizaciÃ³n
- Base sÃ³lida para despliegue en producciÃ³n
- Enfatiza habilidades clave requeridas por **Bluetab**:
  - InterpretaciÃ³n de datos
  - Arquitectura distribuida
  - Calidad, testing, CI/CD y documentaciÃ³n clara
